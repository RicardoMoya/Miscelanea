{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medición de Tiempos: Python, Numpy vs GPU (TensorFlow)\n",
    "\n",
    "* En este notebook vamos a medir los tiempos de ejecución en la multiplicción de 2 matrices usando:\n",
    "\n",
    "    - **Python - CPU**: implementación \"tradicional\" para la multiplicación de 2 Matrices.\n",
    "    - **Numpy - CPU**: Llamando al método *.dot()* para la multiplicación de matrices.\n",
    "    - **TensorFlow - GPU**: Definidos dos tensores y los multiplicamos con el método *.multiply()*. Para esta ejecución se hará uso de la GPU \"Nvidia GeForce RTX 2060\" con:\n",
    "        + Drivers instalados\n",
    "        + CUDA (versión 10.1)\n",
    "        + CUDNN (versión 7)\n",
    "        + TensorFlow (versión 2.3.0)\n",
    "        \n",
    "        \n",
    "<hr>\n",
    "\n",
    "\n",
    "### Definimos 2 matrices aleatorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Tamaño de la matriz SIZExSIZE\n",
    "SIZE = 500\n",
    "a = np.random.rand(SIZE, SIZE)\n",
    "b = np.random.rand(SIZE, SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.- Python - CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 3s ± 763 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "result = np.zeros((SIZE, SIZE))\n",
    "for i in range(SIZE):\n",
    "    for j in range(SIZE):\n",
    "        for k in range(SIZE):\n",
    "            result[i,j] += a[i,k] * b[k,j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.- Numpy - CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.79 ms ± 159 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x = np.dot(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.- TensorFlow - GPU\n",
    "\n",
    "* En primer lugar:\n",
    "    - Limitamos el uso de la memoria de la GPU (recomendable para que no \"casquen\" nuestros programas)\n",
    "    - Mostramos la información relativa a la GPU y las versiones de CUDA y CUDNN instaladas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### INFORMACIÓN ####\n",
      "  Versión de TensorFlow: 2.3.0\n",
      "  GPU: [('/device:GPU:0', 'device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5')]\n",
      "  Versión Cuda  -> 64_101\n",
      "  Versión Cudnn -> 64_7\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Limitación la memoria de la GPU\n",
    "config = tf.compat.v1.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))\n",
    "\n",
    "# Permitir crecimiento de la memoria\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    print('Invalid device or cannot modify virtual devices once initialized.')\n",
    "\n",
    "\n",
    "print('#### INFORMACIÓN ####')\n",
    "print('  Versión de TensorFlow: {}'.format(tf.__version__))\n",
    "print('  GPU: {}'.format([(x.name, x.physical_device_desc)\n",
    "                          for x in tf.python.client.device_lib.list_local_devices() if x.device_type == 'GPU']))\n",
    "print('  Versión Cuda  -> {}'.format(tf.sysconfig.get_build_info()['cuda_version']))\n",
    "print('  Versión Cudnn -> {}'.format(tf.sysconfig.get_build_info()['cudnn_version']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pasamos las matrices a tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos los tensores\n",
    "ta = tf.convert_to_tensor(a)\n",
    "tb = tf.convert_to_tensor(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Multiplicamos los tensores (con GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.3 µs ± 36.7 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "result = tf.math.multiply(ta,tb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
